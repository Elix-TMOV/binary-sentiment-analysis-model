{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7742066b-b85b-48e2-a076-4dd2a864f602",
   "metadata": {},
   "source": [
    "Okay so this is where I will be using pytorch to do some sentiment analysis using my gpu\n",
    "I will be using the imdb data set, load it up\n",
    "Tokenize it.\n",
    "Make embeddings out of it, (matter of fact it's gonna happen as I train)\n",
    "I will train a tansformer model to learn sentiment distibution from the data\n",
    "If it is not overfitting then I will be able to stack layers until it does\n",
    "If it starts to overfit i will randomly drop some data in the hidden layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c6a22e-118c-48eb-a112-e38ef495e617",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.data.utils import get_tokenizer  # Updated location\n",
    "from torchtext.vocab import build_vocab_from_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1988120d-bd1a-4ae3-8cfc-01f714279a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(build_vocab_from_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ca278c-a529-4f6d-9454-000a62d46b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "imdb_dir = os.path.join(os.getcwd(), 'aclImdb')\n",
    "\n",
    "train_dir = os.path.join(imdb_dir, 'test')\n",
    "\n",
    "train_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d09e34f-f1a3-4a41-8776-752fc11491f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "texts = []\n",
    "for label in ['neg', 'pos']:\n",
    "    dir_name = os.path.join(train_dir, label)\n",
    "    for fname in os.listdir(dir_name):  # Change 'file' to 'fname'\n",
    "        # Check if it is a text file\n",
    "        if fname.endswith('.txt'):\n",
    "            with open(os.path.join(dir_name, fname), 'r', encoding='utf-8') as f:\n",
    "                texts.append(f.read())\n",
    "                if label == 'neg':\n",
    "                    labels.append(0)\n",
    "                else:\n",
    "                    labels.append(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792e31cd-8c5d-4340-9e2d-4276bd37786a",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(build_vocab_from_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c6325f-263f-43c5-8724-54f720fed671",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "def yield_tokens(data_iter):\n",
    "    for text in data_iter:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "\n",
    "vocab = build_vocab_from_iterator(yield_tokens(texts), specials = [\"<unk>\", \"<pad>\"], max_tokens=20000)\n",
    "\n",
    "vocab.set_default_index(vocab[\"<unk>\"])  # Set <unk> as the default for out-of-vocab words\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71c1a53c-8a93-448a-b67c-e12688530a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def numericalize(texts, max_len):\n",
    "    sequences = []\n",
    "    for text in texts:\n",
    "        tokens = tokenizer(text)\n",
    "        numericalized_tokens = [vocab[token] for token in tokens]\n",
    "\n",
    "        if len(numericalized_tokens) > max_len:\n",
    "            numericalized_tokens = numericalized_tokens[:max_len]\n",
    "        else:\n",
    "            numericalized_tokens.extend([vocab[\"<pad>\"]] * (max_len - len(numericalized_tokens)))\n",
    "\n",
    "        sequences.append(torch.tensor(numericalized_tokens))\n",
    "    \n",
    "    return torch.stack(sequences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33bb0a61-6bc0-40d6-a5a8-814a43d15205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 12070\n",
      "Validation dataset size: 3448\n",
      "Test dataset size: 1725\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "\n",
    "# Convert texts and labels to tensors\n",
    "label_tensor = torch.tensor(labels)\n",
    "numericalized_texts = numericalize(texts, max_len=300)\n",
    "\n",
    "# Create dataset and dataloaders\n",
    "dataset = TensorDataset(numericalized_texts, label_tensor)\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.2 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Optionally, print out the sizes of the splits\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c90e3ff-77ce-4479-8f44-c706ee0ad4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcc2df16-e242-479a-be44-bd48807f5ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n",
      "11.8\n",
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())  # Should print True if CUDA is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdde6e2-17d7-4be4-8aa8-4670b7da603f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device\n",
    "# check if the GPU is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64903c72-6a2d-4061-83b7-7483a37ff44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d776fb-6da0-4a0e-a441-a84bbbdf90b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition\n",
    "class SentimentModel(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, nhead, num_layers, hidden_dim, output_dim):\n",
    "        super(SentimentModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=emb_dim, \n",
    "            nhead=nhead, \n",
    "            dim_feedforward=hidden_dim, \n",
    "            activation='relu',\n",
    "            dropout = 0.5,\n",
    "            batch_first=True  # Ensure [batch_size, seq_len, emb_dim] order\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)\n",
    "        self.fc_dropout = nn.Dropout(0.5)  # 50% dropout rate\n",
    "        self.fc = nn.Linear(emb_dim, output_dim)\n",
    "        \n",
    "        \n",
    "    def forward(self, x, src_mask=None):\n",
    "        embedded = self.embedding(x)  # shale of the embedding [batch_size, seq_len, emb_dim]\n",
    "       \n",
    "        src_key_padding_mask = (x == vocab[\"<pad>\"])  # Use pad_idx to detect padding tokens\n",
    "\n",
    "        \n",
    "\n",
    "        # Pass through the transformer with the padding mask\n",
    "        transformer_output = self.transformer(\n",
    "            src=embedded, \n",
    "            src_key_padding_mask=src_key_padding_mask, \n",
    "        )\n",
    "\n",
    "        transformer_output = self.fc_dropout(transformer_output)\n",
    "\n",
    "        # Use the output of the last token or mean pooling\n",
    "        \n",
    "        output = transformer_output.mean(dim=1)\n",
    "        \n",
    "        final_output = self.fc(output)  # [batch_size, output_dim]\n",
    "\n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0dc5c715-48d1-4c59-98aa-20dadcaae70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentimentModel(vocab_size=20000, emb_dim=256, nhead=8, num_layers=3, hidden_dim=512, output_dim=2)\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50704e0e-80cb-4fac-8f67-573a90f24b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, num_epochs=10):\n",
    "    train_losses, val_losses, val_accuracies = [], [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            texts, labels = batch\n",
    "            texts, labels = texts.to(device), labels.to(device)  # Move to GPU\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(texts)\n",
    "            # print('mobel outputs', outputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            # print('this is the training loss', loss)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                texts, labels = batch\n",
    "                texts, labels = texts.to(device), labels.to(device)  # Move to GPU\n",
    "\n",
    "                outputs = model(texts)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "        \n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_accuracy = correct / total\n",
    "        val_losses.append(avg_val_loss)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], \"\n",
    "              f\"Train Loss: {avg_train_loss:.4f}, \"\n",
    "              f\"Val Loss: {avg_val_loss:.4f}, \"\n",
    "              f\"Val Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "    return train_losses, val_losses, val_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b94721-1762-42b4-a009-c23bd29868a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_losses, val_losses, val_accuracies = train_model(model, train_loader, val_loader, num_epochs=10)\n",
    "torch.save(model.state_dict(), os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2832414a-dd91-420a-8a68-547030843745",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def test_model(model, test_loader):\n",
    "    test_accuracy = 0\n",
    "    test_loss = 0\n",
    "    correct = 0  # Initialize correct predictions count\n",
    "    total = 0    # Initialize total samples count\n",
    "    all_pred = []\n",
    "    all_labels = []\n",
    "    \n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Disable gradient calculation during testing to save memory and computation\n",
    "    with torch.no_grad():  # Corrected: added parentheses to use torch.no_grad as a context manager\n",
    "        for test_batch in test_loader:\n",
    "            texts, labels = test_batch\n",
    "            texts, labels = texts.to(device), labels.to(device)  # Move to GPU if needed\n",
    "\n",
    "            # Forward pass: get predictions\n",
    "            predictions = model(texts)\n",
    "            loss = criterion(predictions, labels)\n",
    "            test_loss += loss.item()  # Fixed: remove arguments from item()\n",
    "\n",
    "            # predictions is a tensor of shape (batch_size, num_classes)\n",
    "            # For example:\n",
    "            # [\n",
    "            #     [2, 8],    -> 80% probability for class 1\n",
    "            #     [6, 4],    -> 60% probability for class 0\n",
    "            #     [9, 1],    -> 90% probability for class 0\n",
    "            #     [3, 7],    -> 70% probability for class 1\n",
    "            # ]\n",
    "            # We want to find the index of the max value in each row, which is the predicted label\n",
    "            _, pred_label = torch.max(predictions, 1)  # Get predicted class indices\n",
    "\n",
    "            all_pred.extend(pred_label.cpu().numpy())  # Corrected: changed 'extends' to 'extend'\n",
    "            all_labels.extend(labels.cpu().numpy())    # Corrected: changed 'extends' to 'extend'\n",
    "            \n",
    "            correct += (pred_label == labels).sum().item()  # Count correct predictions\n",
    "            total += labels.size(0)  # Count total samples\n",
    "            \n",
    "    # Calculate test accuracy\n",
    "    test_accuracy = correct / total\n",
    "    avg_test_loss = test_loss / len(test_loader)  # Average test loss\n",
    "    \n",
    "    # Print or return results\n",
    "    report = classification_report(all_labels, all_pred, target_names=['Class 0', 'Class 1'])  # Use your actual class names\n",
    "    print(f\"Test Loss: {avg_test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n",
    "    print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db3c26dc-2dbb-48d3-8e9e-f14c0a5e6f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.4478, Test Accuracy: 0.9043\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.92      0.94      0.93      1226\n",
      "     Class 1       0.85      0.81      0.83       499\n",
      "\n",
      "    accuracy                           0.90      1725\n",
      "   macro avg       0.89      0.88      0.88      1725\n",
      "weighted avg       0.90      0.90      0.90      1725\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461fc2c7-72c2-46f8-bddf-5562321bbacf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 300])\n",
      "tensor([[127,   0,  10, 811,   4,  42,  10, 127, 406,   4,  90,  77,  25,  62,\n",
      "           0, 361,  39,   7,  14,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "prompt =\"This product is great! I love it. It works perfectly and exceeded my expectations. Highly recommend it to everyone!\"\n",
    "tokenized_prompt = numericalize([prompt], max_len=300) \n",
    "\n",
    "# Move the tokenized prompt to the same device as the model\n",
    "print(tokenized_prompt.shape)\n",
    "\n",
    "tokenized_prompt = tokenized_prompt.to(device)\n",
    "print(tokenized_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "697fd26a-5e49-48e9-8b8b-1075e84b2c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "negative\n"
     ]
    }
   ],
   "source": [
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Inference without gradient calculation\n",
    "with torch.no_grad():\n",
    "    output = model(tokenized_prompt)\n",
    "    probabilities = torch.sigmoid(output)  # Corrected line\n",
    "    _, label = torch.max(probabilities, 1)\n",
    "    print(label.item())\n",
    "    if label.item() == 1:\n",
    "        print ('positive')\n",
    "    else:\n",
    "        print('negative')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4df6fe0-4485-4e59-bc0e-b9b5aa5522ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss and accuracy\n",
    "epochs = range(1, len(train_losses) + 1)\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, train_losses, label='Train Loss')\n",
    "plt.plot(epochs, val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot validation accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, val_accuracies, label='Validation Accuracy', color='g')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "78e4cc4a-71b0-4b5d-8698-a58487b531a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'trained_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93fa0cc-9e02-4e9d-8b82-6789d35e3aea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
